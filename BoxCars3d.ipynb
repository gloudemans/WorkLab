{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to be able to train a variety of models using a variety of datasets and evaluate their performance in various ways. It would be helpful to develop a framework to train such combinations.\n",
    "\n",
    "To support generalized usage, compatible datasets should implement a consistent interface:\n",
    "* Derive from PyTorch Dataset\n",
    "* Provide methods to query the number of classes, class indices, and class names\n",
    "* Provide methods to query image dimension\n",
    "\n",
    "Compatible models should include:\n",
    "* ?\n",
    "\n",
    "Compatible evaluators should implement a consistent interface:\n",
    "* Initialize split (split type)\n",
    "* Batch statistic (split type, class activations, ground truth)\n",
    "* Epoch summary\n",
    "* Training summary\n",
    "\n",
    "The test framework should provide means to construct an experiment combining dataset, model, and evaluation objects.\n",
    "\n",
    "Experiment(model, dataset, evaluator)\n",
    "train(optimizer, ...)\n",
    "validate\n",
    "\n",
    ", and \n",
    "Develop a generalized classifier development bench. The development should accept an arbitary classificationallow me to create models\n",
    "\n",
    "object that c\n",
    "Train Model\n",
    "Test Model\n",
    "Save Model\n",
    "Load Model\n",
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Experiment:\n",
    "    \"\"\"Classifier experiment test bench.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, dataset, transforms, metrics, hyperparamters):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.11.0\n",
      "Torchvision Version:  0.12.0\n",
      "Work file /data/boxcars3d/boxcars3d.zip is already available.\n",
      "Work file /data/boxcars3d/boxcars3d.zip is already available.\n",
      "Training split contains   93028 images.\n",
      "Validation split contains   11629 images.\n"
     ]
    }
   ],
   "source": [
    "%reset -f \n",
    "\n",
    "# Import a lot of stuff\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "#from dvmcar import DvmCarDataset\n",
    "from boxcars3d import BoxCars3dDataset\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "local = True\n",
    "\n",
    "if local:\n",
    "    #work_def = '/data/dvmcar/dvmcar.zip'\n",
    "    work_def = '/data/boxcars3d/boxcars3d.zip'    \n",
    "    persist_def = None\n",
    "else:\n",
    "    #work_def = '/home/ubuntu/WorkLab/data/dvmcar/dvmcar.zip'\n",
    "    work_def = '/home/ubuntu/WorkLab/data/boxcars3d/boxcars3d.zip'\n",
    "    #persist_def = '/home/ubuntu/worklab/dvmcar.zip'\n",
    "    persist_def = '/home/ubuntu/worklab/boxcars3d.zip'\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 10\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Resnet input height & width?\n",
    "input_size  = 224\n",
    "\n",
    "# Training minibatch size\n",
    "# Higher number are more computationally efficient but might slow convergence\n",
    "batch_size  = 50\n",
    "\n",
    "# Shuufle data between epochs\n",
    "shuffle     = True\n",
    "\n",
    "# Set the fraction of the dataset to use.\n",
    "# Normally this should be 1, but values less than one decrease the number of samples per epoch\n",
    "scale = 1\n",
    "\n",
    "# Set partions for train, test, and validate subsets\n",
    "partition0  = 0.8*scale\n",
    "partition1  = 0.9*scale\n",
    "partition2  = 1.0*scale\n",
    "\n",
    "# Define corresponding split arguments for the dataset constructor\n",
    "train_split = [0,          partition0]\n",
    "val_split   = [partition0, partition1]\n",
    "test_split  = [partition1, partition2]\n",
    "\n",
    "# Specify training transform stack\n",
    "# Not too sure what random resize crop does...\n",
    "# Per Derek - maybe color space & other distortions would be useful?\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "\n",
    "# Specify vaidation transform stack\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "\n",
    "#train_data  = DvmCarDataset(split = train_split, transform = train_transform, work = work_def, persist = persist_def)\n",
    "#val_data    = DvmCarDataset(split =   val_split, transform =   val_transform, work = work_def, persist = persist_def)\n",
    "train_data  = BoxCars3dDataset(split = train_split, transform = train_transform, work = work_def, persist = persist_def)\n",
    "val_data    = BoxCars3dDataset(split =   val_split, transform =   val_transform, work = work_def, persist = persist_def)\n",
    "\n",
    "print('Training split contains {:7} images.'.format(len(train_data)))\n",
    "print('Validation split contains {:7} images.'.format(len(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_fields = [l.split() for l in train_data.label_list]\n",
    "mm_fields = list(set([r[0]+','+r[1] for r in label_fields]))\n",
    "mm_fields.sort()\n",
    "\n",
    "with open('boxcars_make_model.csv','w') as out:\n",
    "    out.write('boxcars3d-make,boxcars3d-model\\n')\n",
    "    for r in mm_fields:\n",
    "        out.write(r+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    \n",
    "    classes = model.fc.out_features\n",
    "    \n",
    "    plt.rcParams['figure.dpi'] = 160\n",
    "\n",
    "    fig = plt.figure() \n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2) \n",
    "\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-')\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            sample = 0\n",
    "                       \n",
    "            rank_count = np.zeros(classes, dtype=np.float)\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                sample += inputs.size(0)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Use maximal classes as predictions\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # Get indices (labels) sorting the vector in decreasing order\n",
    "                    top_indices = torch.argsort(outputs, 1, descending=True)\n",
    "                    \n",
    "                    # Find predicted ranking of the true class for each result in the batch\n",
    "                    n = [(top_indices[k]==labels.data[k]).nonzero().squeeze().item() for k in range(len(labels.data))]\n",
    "                    \n",
    "                    # For each result in the batch...\n",
    "                    for idx in n:\n",
    "                        \n",
    "                        # Increment\n",
    "                        rank_count[idx] += 1\n",
    "\n",
    "                    # Update plot\n",
    "                    \n",
    "                    fig.suptitle('Top N Summary: phase={}, epoch={:3}, sample={:8}'.format(\n",
    "                        phase, epoch, sample))\n",
    "\n",
    "                    clear_output(wait = True)\n",
    "                    x = np.arange(classes)+1\n",
    "                    \n",
    "                    ax1.cla()\n",
    "                    ax1.plot(x,          rank_count /sample, label='P(rank==N)')\n",
    "                    ax1.plot(x,np.cumsum(rank_count)/sample, label='P(rank in 1..N)')\n",
    "                    ax1.set_title('All classes')\n",
    "                    ax1.legend()\n",
    "                    ax1.grid()\n",
    "                    ax1.set_ylabel('Probability')\n",
    "                    ax1.set_xlabel('N')    \n",
    "\n",
    "                    max_n = 20\n",
    "                    ax2.cla()\n",
    "                    ax2.plot(x[:max_n],          rank_count[:max_n] /sample, label='P(rank==N)', linestyle='None', marker='o')\n",
    "                    ax2.plot(x[:max_n],np.cumsum(rank_count[:max_n])/sample, label='P(rank in 1..N)', linestyle='None', marker='o')\n",
    "                    ax2.set_title('Top {} classes'.format(max_n))\n",
    "                    ax2.legend()\n",
    "                    ax2.grid()\n",
    "                    ax2.set_ylabel('Probability')\n",
    "                    ax2.set_xlabel('N')    \n",
    "                    \n",
    "                    display(fig)    \n",
    " \n",
    "                    print('Epoch={:3} / Sample={:8}'.format(epoch, sample), end='\\r', flush=True)\n",
    "                \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n",
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Training model...\n",
      "Epoch 0/9\n",
      "-\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute '__spec__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-af54ac05007a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# Train and evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mmodel_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"inception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-d24886e52523>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# Iterate over data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mprep_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_preparation_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# read end of pipe will be \"stolen\" by the child process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\spawn.py\u001b[0m in \u001b[0;36mget_preparation_data\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;31m# or through direct execution (or to leave it alone entirely)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mmain_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mmain_mod_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmain_mod_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'init_main_from_name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_mod_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__spec__'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x640 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, train_data.classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "# print(model_ft)\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {'train': train_data, 'val' : val_data}\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=8) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=0.05)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Training model...\")\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001F535967548>\n"
     ]
    }
   ],
   "source": [
    "print(dataloaders_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
